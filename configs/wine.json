{
    "layers": [
        {
            "input_size": 12,
            "output_size": 2,
            "activation_function": "relu"
        },
        {
            "input_size": 2,
            "output_size": 2,
            "activation_function": "softmax"
        }
    ],
    "epochs": 16,
    "alpha": 16
}